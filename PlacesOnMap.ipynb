{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize le texte\n",
    "Une texte pour l'ordinateur est un 'string', une liste de characters. On aura besoin d'une liste de mots et on appelle ce processus 'tokenisation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chronicon', 'beneuentanum', 'falcone', 'beneuento', 'chronicon', 'beneuentanum', '1102.1.1', 'apud', 'urbem']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"/Users/danjane/cltk_data/latin/text/latin_text_latin_library/falcone.txt\", \"r\") \n",
    "text = file.read()\n",
    "\n",
    "# Remplace j/v et tokenize\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "\n",
    "jv_replacer = JVReplacer()\n",
    "text = jv_replacer.replace(text.lower())\n",
    "\n",
    "word_tokenizer = WordTokenizer('latin')\n",
    "text_word_tokens = word_tokenizer.tokenize(text)\n",
    "text_word_tokens = [token for token in text_word_tokens if token not in ['.', ',', ':', ';','*']]\n",
    "\n",
    "# Garde les mots de plus de trois characters\n",
    "text_word_tokens = [token for token in text_word_tokens if len(token) > 3]\n",
    "\n",
    "# Montre les premiers mots ('tokens') trouvé\n",
    "print(text_word_tokens[:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer une dictionnaire pour les noms des lieux\n",
    "On a besoin d'une grande liste des noms latins des lieux, et aussi un moyen de les traduires dans leurs noms moderns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical latin name (source(s): variant(s)), english name (native language(s)) - older name(s)\n",
      "canonical latin name (source(s): variant(s)), (other language(s))\n",
      "canonical latin name (source(s): variant(s)), location(s)\n",
      "brigantium, bregenz\n",
      "brigantia, bregenz\n",
      "carnuntum, bad deutsch-altenburg / petronell\n",
      "chremisa, krems\n",
      "idunum, judenburg\n",
      "iuenna, jaunstein - (podjuna)\n",
      "iuenna, völkermarkt\n"
     ]
    }
   ],
   "source": [
    "file = open(\"LatinGeographicalNames.txt\")\n",
    "file_text = file.read().lower()\n",
    "file_text_lines = file_text.split('\\n')\n",
    "latinname_modernname = [line.split('\\t') for line in file_text_lines]\n",
    "\n",
    "latin_names = []\n",
    "modern_names = []\n",
    "for pair in latinname_modernname:\n",
    "    if len(pair) > 1:\n",
    "        latins = pair[0].split(',')\n",
    "        moderns = pair[1].split(',')\n",
    "        for latin in latins:\n",
    "            for modern in moderns:\n",
    "                latin_names.append(latin.lstrip())\n",
    "                modern_names.append(modern.lstrip())\n",
    "\n",
    "for i in range(10):\n",
    "        print(latin_names[i] + ', ' + modern_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['solium', 'regalis', 'curia', 'luna']\n"
     ]
    }
   ],
   "source": [
    "places_in_text = list(set(text_word_tokens) & set(latin_names))\n",
    "print(places_in_text[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je voudrais trouver des textes avec les plus de lieux possible, car il serait plus jolie sur un plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#files = [file in os.listdir(\n",
    "#    \"/Users/danjane/cltk_data/latin/text/latin_text_latin_library/\")]\n",
    "dir_texts = \"/Users/danjane/cltk_data/latin/text/latin_text_latin_library/\"\n",
    "files = os.listdir(dir_texts)\n",
    "files = [file for file in files if (file.endswith('.txt')) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    jv_replacer = JVReplacer()\n",
    "    text = jv_replacer.replace(text.lower())\n",
    "\n",
    "    word_tokenizer = WordTokenizer('latin')\n",
    "    text_word_tokens = word_tokenizer.tokenize(text)\n",
    "    text_word_tokens = [token for token in text_word_tokens if token not in ['.', ',', ':', ';','*']]\n",
    "\n",
    "    # Garde les mots de plus de trois characters\n",
    "    text_word_tokens = [token for token in text_word_tokens if len(token) > 3]\n",
    "    return text_word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_places = {}\n",
    "for file in files:\n",
    "    file = open(os.path.join(dir_texts, file), \"r\") \n",
    "    text = file.read()\n",
    "    tokens = tokenize(text)\n",
    "    num_of_places[file] = len(set(tokens) & set(latin_names))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/Users/danjane/cltk_data/latin/text/latin_text_latin_library/pliny.nh3.txt' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='/Users/danjane/cltk_data/latin/text/latin_text_latin_library/pomponius2.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "biggest = np.max(list(num_of_places.values()))\n",
    "for (key, value) in num_of_places.items():\n",
    "    if value==biggest:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quadrata': 'lébény', 'columna': 'kolomna', 'tolosa': 'toulouse', 'nemausus': 'nîmes', 'massilia': 'marseille', 'nicaea': 'nice', 'bononia': 'boulogne-sur-mer', 'arelate': 'arles - (arle)', 'theodosia': 'feodosiya', 'altinum': 'kölked', 'colonia': 'kolín', 'luna': 'louny'}\n"
     ]
    }
   ],
   "source": [
    "# file = '/Users/danjane/cltk_data/latin/text/latin_text_latin_library/pliny.nh3.txt'\n",
    "file = '/Users/danjane/cltk_data/latin/text/latin_text_latin_library/pomponius2.txt'\n",
    "\n",
    "file = open(file, \"r\")\n",
    "text = file.read()\n",
    "word_tokens = tokenize(text)\n",
    "\n",
    "places_in_text = set(word_tokens) & set(latin_names)\n",
    "\n",
    "places_lookup = {}\n",
    "for place in places_in_text:\n",
    "    lookedup = [modern_name for \n",
    "           (latin_name, modern_name) in zip(latin_names, modern_names) \n",
    "           if latin_name==place]\n",
    "    if len(lookedup):\n",
    "        places_lookup[place] = lookedup[0]\n",
    "    else:\n",
    "        print('no place?   ' + place)\n",
    "            \n",
    "print(places_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quadrata': (47.737851, 17.3927637), 'columna': (55.0937517, 38.7688618), 'tolosa': (43.604652, 1.444209), 'nemausus': (43.836699, 4.360054), 'massilia': (43.296482, 5.36978), 'nicaea': (43.7101728, 7.261953200000001), 'bononia': (50.725231, 1.613334), 'arelate': (43.676647, 4.6277769), 'theodosia': (45.031933, 35.382433), 'altinum': (45.9489796, 18.7058024), 'colonia': (50.02732899999999, 15.2027277), 'luna': (50.35398120000001, 13.8033551)}\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import GoogleV3\n",
    "\n",
    "# Lire le passmot\n",
    "file = open(\"google_api_key.txt\", \"r\") \n",
    "api_key = file.read()\n",
    "geolocator = GoogleV3(api_key = api_key)\n",
    "\n",
    "places_latlng = {}\n",
    "for (latin, modern) in places_lookup.items():\n",
    "    place, (lat, lng) = geolocator.geocode(modern, timeout=15)\n",
    "    places_latlng[latin] = (lat, lng)\n",
    "    \n",
    "print(places_latlng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.2043907"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create an interactive .html mapping with Folium\n",
    "import folium\n",
    "\n",
    "latitude = 47\n",
    "longitude = 7\n",
    "screen_name = 'pomponius2'\n",
    "\n",
    "tmap=folium.Map(location=[latitude,longitude],\n",
    "               zoom_start=6,tiles='OpenStreetMap')\n",
    "\n",
    "fg=folium.FeatureGroup(name=\"Locations\")\n",
    "\n",
    "for latin, (lat, lng) in places_latlng.items():\n",
    "    fg.add_child(folium.Marker(location=[lat,lng],popup=(folium.Popup(latin)),\n",
    "                               icon=folium.Icon(color='green',icon_color='green')))\n",
    "\n",
    "tmap.add_child(fg)\n",
    "\n",
    "tmap.add_child(folium.LayerControl())\n",
    "tmap.save(outfile=screen_name+'_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
